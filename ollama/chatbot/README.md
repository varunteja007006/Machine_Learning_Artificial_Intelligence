# Project setups : (linux mint)

## Frontend setup:

Frontend is nextjs, you can install the dependencies and run the app with the following commands.

```sh
npm install
npm run dev
```

## Local AI setup:

Download the ollama and model to hit the local api at port 11434.

Download Ollama here: https://ollama.com/

Download the model (llama 3.2): https://ollama.com/library/llama3.2

ollama run llama3.2 in terminal
